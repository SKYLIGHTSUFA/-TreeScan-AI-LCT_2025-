import time, torch
from image_utils import load_image_tensor


def get_detailed_analysis(
    image_pil, model, tokenizer, device, torch_dtype, tree_description=""
):
    """
    Детальный анализ + автоматическая сводка:
    объединяет Главное и Дополнительное описание в единый текст,
    который записывается в поле 'Дополнительное описание'.
    """
    # --- 1. Получаем/создаём главное описание ---
    main_desc = tree_description
    if not main_desc:
        q = "<image>\n" "Дай краткое главное описание объекта на изображении."
        with torch.no_grad():
            main_desc = model.chat(
                tokenizer,
                load_image_tensor(image_pil.resize((448, 448))).to(
                    dtype=torch_dtype, device=device
                ),
                q,
                dict(
                    max_new_tokens=200,
                    do_sample=False,
                    pad_token_id=tokenizer.pad_token_id,
                ),
            ).strip()

    # --- 2. Основные вопросы + ваши доп. вопросы ---
    questions = {
        "Оценка здоровья": (
            "Оцени здоровье растения числом от 1 до 10. "
            "Формат: 'Здоровье: N баллов из 10'."
        ),
        "Вид и порода": (
            "Определи вид растения по изображению. "
            "Верни ровно одно название из списка: "
            "'Берёза, Клен, Дуб, Кедр, Ива, Тополь, Сосна, Ель, Туя, Рябина, Каштан, Осина, Липа, Ясень, фруктовые растения'. "
            "Если кустарник – выбери одно название из списка кустарников. "
            "Формат ответа: 'Вид и порода: <одно название>. Тип: дерево/кустарник/пень.'"
        ),
        "Дефектоскопия": (
            "Перечисли видимые дефекты: трещины, дупла, сломанные ветви, "
            "механические повреждения, отслоение коры и т.д. "
            "Если их нет, напиши: 'Дефектов не обнаружено'."
        ),
        # --- Дополнительные точечные вопросы ---
        "Механические повреждения": "Присутствуют ли какие-то механические повреждения на растении? Ответь максимально четко и коротко",
        "Трещины": "Присутствуют ли какие-то трещины на растении? Ответь максимально четко и коротко",
        "Гниль": "Присутствует ли гниль на растении? Ответь максимально четко и коротко",
        "Отслоение коры": "Присутствует ли отслоение коры на растении? Ответь максимально четко и коротко",
        "Обширное дупло": "Присутствует ли обширное дупло на растении? Ответь максимально четко и коротко",
        "Обширная сухобочина": "Присутствует ли обширная сухобочина на растении? Ответь максимально четко и коротко",
        "Процент сухих ветвей": (
            "Оцени процент сухих ветвей и выбери только один вариант: "
            "0-25%, 25-50%, 50-75%, или 75-100%. "
            "Формат: 'Сухие ветви: <вариант>'. "
        ),
        "Угол наклона": "Оцени угол наклона дерева. Формат: 'Угол наклона: N градусов'.",
        "Дополнительное описание": (
            "Дай развёрнутое описание окружения и особенностей растения."
        ),
    }

    results = {"Главное описание": main_desc}
    pixel_values = load_image_tensor(image_pil.resize((448, 448))).to(
        dtype=torch_dtype, device=device
    )

    for key, q in questions.items():
        prompt = f"<image>\nГлавное описание: {main_desc}\n\n{q}"
        with torch.no_grad():
            resp = model.chat(
                tokenizer,
                pixel_values,
                prompt,
                dict(
                    max_new_tokens=300,
                    do_sample=False,
                    pad_token_id=tokenizer.pad_token_id,
                ),
            )
        results[key] = resp.strip()
        time.sleep(0.25)

    # --- 3. Автоматическая сводка ---
    extra_desc = results.get("Дополнительное описание", "")
    if extra_desc:
        merge_prompt = (
            f"Главное описание: {main_desc}\n"
            f"Дополнительное описание: {extra_desc}\n\n"
            "Объедини оба текста в единый связный абзац, убери повторы, "
            "сохрани все уникальные факты. Ответ одним абзацем."
        )
        with torch.no_grad():
            merged = model.chat(
                tokenizer,
                pixel_values,
                merge_prompt,
                dict(
                    max_new_tokens=350,
                    do_sample=False,
                    pad_token_id=tokenizer.pad_token_id,
                ),
            ).strip()
        results["Дополнительное описание"] = merged

    return results
